{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 环境配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 创建conda环境，指定python版本为3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "conda create -n traffic_sim_dl python=3.9\n",
    "conda activate traffic_sim_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 安装所需Python依赖文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install ipykernel\n",
    "pip install hydra-core==1.1.1\n",
    "pip install pytorch-lightning==1.5.10\n",
    "pip install transforms3d==0.3.1\n",
    "pip install opencv-python==4.5.5.64\n",
    "pip install gym==0.25.2\n",
    "pip install waymo-open-dataset-tf-2-12-0==1.6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 安装NVidia驱动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 可通过下列如下指令查看是否安装成功\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 安装CUDA和cuDNN\n",
    "\n",
    "> 推荐使用 CUDA 11.3 cuDNN 8.2.1\n",
    "\n",
    "> 安装方法参考文章：https://www.jianshu.com/p/8fbfc2e1c6a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 查看安装的CUDA版本\n",
    "nvcc -V\n",
    "\n",
    "# 查看安装的cuDNN版本\n",
    "cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 安装与cuda版本匹配的pytorch\n",
    "\n",
    "> 推荐使用 pytorch 1.11.0+cu113\n",
    "\n",
    "> 下载地址：https://pytorch.org/get-started/previous-versions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# PIP安装\n",
    "pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "# CONDA安装（二选一）\n",
    "conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=11.3 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TensorFlow------------------\n",
      "Num GPUs Available:  1\n",
      "--------------------Pytorch--------------------\n",
      "使用的设备： NVIDIA RTX 3500 Ada Generation Laptop GPU\n",
      "使用的设备类型： cuda\n",
      "PyTorch 版本： 1.11.0\n",
      "CUDA 版本： 11.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"------------------TensorFlow------------------\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import torch\n",
    "print(\"--------------------Pytorch--------------------\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"使用的设备：\", torch.cuda.get_device_name(0))  # 获取第一个 CUDA 设备的名称\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA 不可用，将使用 CPU。\")\n",
    "\n",
    "print(\"使用的设备类型：\", device)\n",
    "print(\"PyTorch 版本：\", torch.__version__)\n",
    "print(\"CUDA 版本：\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 注册Weights And Biases账号，安装本地wandb库并登录\n",
    "\n",
    "> 网址：https://wandb.ai/home\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 安装wandb库\n",
    "pip install wandb==0.15.12\n",
    "\n",
    "# 登录wandb账号\n",
    "wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 修改模型配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 修改数据集所在文件夹路径\n",
    "\n",
    "    打开`config/datamodule/h5_womd.yaml`文件并修改`data_dir`字段指向数据文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 修改Weights And Biases日志记录信息\n",
    "\n",
    "    打开`config/loggers/wandb.yaml`文件并修改相应字段\n",
    "\n",
    "    + project: 项目名称，需要在wandb网站创建\n",
    "    + entity: 用户名\n",
    "    + group: 运行所在组的名称（自定义）\n",
    "    + job_type: 运行的任务类型（训练、验证、测试）\n",
    "    + name: 该次运行任务名称（自定义）\n",
    "    + notes: 该次运行任务说明（自定义）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 进行模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 修改模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch（批次）是一次性送入模型进行训练或推理的数据样本集合。在深度学习中，数据通常分成若干个批次，以便于高效处理和利用计算资源。\n",
    "\n",
    "+ 大小：批次的大小（batch_size）指每个批次中包含的数据样本数。\n",
    "+ 处理：每个批次数据都会经过前向传播、计算损失、反向传播以及更新模型参数。\n",
    "\n",
    "Step（步）通常指一次参数更新的过程。在每个步中，模型会处理一个批次的数据，进行一次前向传播和反向传播，并更新模型参数。\n",
    "\n",
    "+ 训练步：在训练过程中，每处理一个批次数据并更新一次模型参数称为一个训练步（training step）。\n",
    "+ 验证步：在验证过程中，每处理一个批次数据并计算一次验证损失或指标称为一个验证步（validation step）。\n",
    "\n",
    "Epoch（周期）是指模型完成对整个训练数据集的一次完整遍历。在一个 epoch 中，模型会依次处理所有的批次，直到所有数据样本都被使用一次。\n",
    "\n",
    "+ 循环：在一个 epoch 中，模型会按顺序处理所有批次的数据，通常在开始新的一轮（epoch）之前对数据进行打乱（shuffle）。\n",
    "+ 次数：训练通常需要多个 epoch，以便模型逐步优化参数并提高性能。\n",
    "\n",
    "三者联系：\n",
    "\n",
    "+ Batch 是数据处理的基本单位，每个 batch 包含多个样本。\n",
    "+ Step 是训练过程中模型参数更新的基本单位，每个 step 处理一个 batch 并更新一次模型参数。（可通过`accumulate_grad_batches`参数调节参数更新频率）\n",
    "+ Epoch 是训练过程中对整个数据集的一次完整遍历。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 修改batch_size\n",
    "\n",
    "    > 参数位置：`config/datamodule/h5_womd.yaml:batch_size`\n",
    "\n",
    "\n",
    "    由于模型喂入的数据量较大，显卡的显存是本模型选用batch_size大小的主要考虑因素。\n",
    "\n",
    "    目前在batch中每添加一组数据会占用**约3GB的显存空间**，因此对于本地24GB显存显卡选用的batch_size值为8。\n",
    "\n",
    "    batch_size选取值大小的影响：\n",
    "    + 较小的batch size：通常会使模型参数更新更加频繁，每次更新会带有更多的随机性，这可以帮助模型逃脱局部最优解，但可能会导致训练过程更加不稳定。\n",
    "    + 较大的batch size：可以使模型参数更新更加稳定，但每次更新的随机性较低，可能导致收敛到局部最优解。此外，较大的batch size会减少每个epoch中的批次数，从而加快单个epoch的训练时间。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 修改Adam优化器的学习率\n",
    "\n",
    "    + Adam优化器是什么？\n",
    "\n",
    "        Adam（Adaptive Moment Estimation）优化器是一种广泛使用的自适应学习率优化算法，它结合了动量方法和RMSProp方法的优点，通过计算梯度的一阶矩和二阶矩的移动平均值来调整学习率。它为每个参数计算自适应的学习率，使得每个参数能够根据其梯度的变化幅度调整学习率。这在梯度不同尺度的情况下尤其有用，可以避免一些参数更新过快或过慢。\n",
    "\n",
    "    + Adam优化器的全局学习率\n",
    "\n",
    "        > 参数位置：`config/model/traffic_bots.yaml:optimizer.lr`\n",
    "\n",
    "        全局学习率是Adam优化器的一个初始超参数，通常用lr表示。这个全局学习率用于整体缩放每个参数的更新步长，调整各参数自适应学习率的大小。\n",
    "\n",
    "        原论文中使用的初始学习率为`3e-4`，参考线性缩放法则（当批量大小增加k倍时，将学习率也增大k倍），原论文中的batch大小为4*6=24，而本机训练时的批大小为8，因此将**初始学习率相应缩小三倍修改为`1e-4`**\n",
    "\n",
    "    + Adam优化器中学习率大小对训练效果的影响\n",
    "\n",
    "        1. 学习率过大\n",
    "\n",
    "            梯度震荡和不稳定：过大的学习率会导致参数更新幅度过大，从而引起梯度震荡，使得损失函数不稳定，甚至可能导致训练过程发散。\n",
    "\n",
    "            跳过最优点：学习率过大会使得优化过程跳过损失函数的最优点，无法收敛到全局最优或局部最优解。\n",
    "\n",
    "        2. 学习率过小\n",
    "\n",
    "            训练速度慢：过小的学习率会使参数更新幅度过小，导致模型需要更多的迭代次数才能达到收敛。这会显著增加训练时间。\n",
    "\n",
    "            局部最优陷阱：虽然小学习率有助于精细调整参数，但也可能会陷入局部最优，难以跳出较差的局部最优点，无法有效地探索整个损失函数空间。\n",
    "\n",
    "        3. 适当的学习率\n",
    "\n",
    "            平衡更新：适当的学习率可以在训练速度和稳定性之间取得平衡，确保参数更新幅度合适，既能快速降低损失函数值，又能稳定收敛。\n",
    "            \n",
    "            有效探索：合适的学习率使模型能够有效地探索损失函数空间，从而找到全局最优或更好的局部最优解。\n",
    "\n",
    "    + 设置阶梯下降学习率调整策略\n",
    "\n",
    "        > 参数位置：`config/model/traffic_bots.yaml:lr_scheduler.gamma/step_size`\n",
    "\n",
    "        随着训练的epoch推进逐渐减小全局学习率。参考论文中的超参数选取梯度下降间隔为7epoch，单次下降幅度为0.5。\n",
    "\n",
    "        调整策略：\n",
    "\n",
    "        1. 初始实验：选择合理的初始值，如step size为10，gamma为0.1。\n",
    "\n",
    "        2. 监控性能：在训练过程中，关注训练损失和验证损失的变化。如果验证损失在下降间隔后没有显著改善，可能需要调整step size或gamma。\n",
    "\n",
    "        3. 逐步调整：根据性能变化逐步调整参数，例如，如果发现学习率下降过快导致训练过早停止，可以增大step size或减小gamma。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 修改训练参数\n",
    "\n",
    "> 参数位置：`config/trainer/default.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pytorch_lightning.Trainer(\n",
    "    limit_train_batches=0.2,        # 每个epoch只使用20%的训练数据\n",
    "    limit_val_batches=50,           # 每个epoch只使用50个epoch的验证数据\n",
    "    limit_test_batches=1.0,         # 测试时使用所有的测试数据\n",
    "    num_sanity_val_steps=1,         # 设置在训练开始前运行验证集的batch数，用于检查训练代码和数据是否正常。设置为0时跳过该检查。\n",
    "    max_epochs=None,                # 没有设定最大epoch数\n",
    "    min_epochs=None,                # 没有设定最小epoch数\n",
    "    log_every_n_steps=200,          # 每200个训练step记录一次日志\n",
    "    gradient_clip_val=5,            # 梯度裁剪值为5（防止梯度爆炸）\n",
    "    track_grad_norm=2,              # 追踪L2范数的梯度\n",
    "    gpus=-1,                        # 使用所有可用的GPU\n",
    "    precision=16,                   # 使用半精度浮点数(FP16)训练\n",
    "    benchmark=False,                # 不启用benchmark\n",
    "    deterministic=False,            # 不要求确定性\n",
    "    sync_batchnorm=False,           # 不同步批量归一化\n",
    "    detect_anomaly=False,           # 不检测训练过程中的异常\n",
    "    accumulate_grad_batches=1,      # 不进行梯度累积（设为2时，每两个batch计算一次梯度）\n",
    "    resume_from_checkpoint=None,    # 不从检查点恢复训练\n",
    "    enable_progress_bar=True        # 启用进度条\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 半精度（FP16）可以在确保数值稳定性的前提下，显著减少存储需求和提高计算速度。在处理大规模数据集或模型、需要优化训练速度和硬件资源使用的情况下，可以考虑使用半精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 运行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 修改`config/run.yaml`中`action`字段为`fit`，将模型指定到训练状态\n",
    "\n",
    "2. 运行`src/run.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import List\n",
    "from pytorch_lightning import seed_everything, LightningDataModule, LightningModule, Trainer, Callback\n",
    "from pytorch_lightning.loggers import LightningLoggerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_dir: ${hydra:runtime.cwd}\n",
      "seed: 2023\n",
      "action: fit\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  limit_train_batches: 0.5\n",
      "  limit_val_batches: 0.5\n",
      "  limit_test_batches: 1.0\n",
      "  num_sanity_val_steps: 0\n",
      "  max_epochs: null\n",
      "  min_epochs: null\n",
      "  log_every_n_steps: 200\n",
      "  gradient_clip_val: 5\n",
      "  track_grad_norm: 2\n",
      "  gpus: -1\n",
      "  precision: 16\n",
      "  benchmark: false\n",
      "  deterministic: false\n",
      "  sync_batchnorm: false\n",
      "  detect_anomaly: false\n",
      "  accumulate_grad_batches: 1\n",
      "  resume_from_checkpoint: null\n",
      "  enable_progress_bar: true\n",
      "model:\n",
      "  _target_: pl_modules.waymo_motion.WaymoMotion\n",
      "  time_step_current: 10\n",
      "  time_step_gt: 90\n",
      "  time_step_end: 90\n",
      "  time_step_sim_start: 1\n",
      "  hidden_dim: 128\n",
      "  n_video_batch: 3\n",
      "  n_joint_future: 6\n",
      "  interactive_challenge: false\n",
      "  pre_processing:\n",
      "    scene_centric:\n",
      "      _target_: data_modules.scene_centric.SceneCentricPreProcessing\n",
      "    input:\n",
      "      _target_: data_modules.sc_input.SceneCentricInput\n",
      "      dropout_p_history: -1\n",
      "      pe_dim: 96\n",
      "      pose_pe:\n",
      "        map: pe_xy_yaw\n",
      "        tl: ${.map}\n",
      "        agent: ${.map}\n",
      "    latent:\n",
      "      _target_: data_modules.sc_latent.SceneCentricLatent\n",
      "      pe_dim: ${..input.pe_dim}\n",
      "      pose_pe: ${..input.pose_pe}\n",
      "      perturb_input_to_latent: false\n",
      "      dropout_p_history: -1\n",
      "      max_meter: 50.0\n",
      "      max_rad: 3.14\n",
      "  model:\n",
      "    _target_: models.traffic_bots.TrafficBots\n",
      "    hidden_dim: ${..hidden_dim}\n",
      "    add_goal_latent_first: false\n",
      "    resample_latent: false\n",
      "    n_layer_tf_as2pl: 3\n",
      "    n_layer_tf_as2tl: 3\n",
      "    tf_cfg:\n",
      "      d_model: ${...hidden_dim}\n",
      "      n_head: 4\n",
      "      dropout_p: 0.1\n",
      "      norm_first: true\n",
      "      bias: true\n",
      "      activation: relu\n",
      "      d_feedforward: 128\n",
      "      out_layernorm: false\n",
      "    input_pe_encoder:\n",
      "      pe_mode: cat\n",
      "      n_layer: 2\n",
      "      mlp_dropout_p: 0.1\n",
      "      mlp_use_layernorm: false\n",
      "    map_encoder:\n",
      "      pool_mode: max\n",
      "      densetnt_vectornet: true\n",
      "      n_layer: 3\n",
      "      mlp_dropout_p: 0.1\n",
      "      mlp_use_layernorm: false\n",
      "    goal_manager:\n",
      "      disable_if_reached: true\n",
      "      goal_predictor:\n",
      "        mode: mlp\n",
      "        n_layer_gru: 3\n",
      "        use_layernorm: true\n",
      "        res_add_gru: true\n",
      "        detach_features: true\n",
      "      goal_attr_mode: dest\n",
      "      goal_in_local: true\n",
      "      dest_detach_map_feature: false\n",
      "    latent_encoder:\n",
      "      latent_dim: 16\n",
      "      temporal_down_sample_rate: 5\n",
      "      shared_post_prior_net: false\n",
      "      shared_transformer_as: true\n",
      "      latent_prior:\n",
      "        dist_type: diag_gaus\n",
      "        n_cat: 8\n",
      "        log_std: -1\n",
      "        use_layernorm: false\n",
      "      latent_post:\n",
      "        dist_type: diag_gaus\n",
      "        n_cat: ${..latent_prior.n_cat}\n",
      "        log_std: ${..latent_prior.log_std}\n",
      "        use_layernorm: ${..latent_prior.use_layernorm}\n",
      "    temporal_aggregate:\n",
      "      mode: max_valid\n",
      "    agent_temporal:\n",
      "      _target_: models.modules.agent_temporal.MultiAgentGRULoop\n",
      "      num_layers: 3\n",
      "      dropout: 0.1\n",
      "    agent_interaction:\n",
      "      n_layer: 3\n",
      "      mask_self_agent: true\n",
      "      detach_tgt: false\n",
      "      attn_to_map_aware_feature: true\n",
      "    add_latent:\n",
      "      mode: cat\n",
      "      res_cat: false\n",
      "      res_add: true\n",
      "      n_layer_mlp_in: 2\n",
      "      n_layer_mlp_out: 2\n",
      "      mlp_in_cfg:\n",
      "        use_layernorm: false\n",
      "        activation: relu\n",
      "        dropout_p: 0.1\n",
      "      mlp_out_cfg: ${.mlp_in_cfg}\n",
      "    add_goal:\n",
      "      mode: ${..add_latent.mode}\n",
      "      res_cat: ${..add_latent.res_cat}\n",
      "      res_add: ${..add_latent.res_add}\n",
      "      n_layer_mlp_in: 3\n",
      "      n_layer_mlp_out: 2\n",
      "      mlp_in_cfg:\n",
      "        use_layernorm: true\n",
      "        activation: relu\n",
      "        dropout_p: 0.1\n",
      "      mlp_out_cfg: ${..add_latent.mlp_in_cfg}\n",
      "    interaction_first: true\n",
      "    n_layer_final_mlp: -1\n",
      "    final_mlp:\n",
      "      use_layernorm: false\n",
      "      activation: relu\n",
      "      dropout_p: 0.1\n",
      "  teacher_forcing_training:\n",
      "    step_spawn_agent: ${..time_step_current}\n",
      "    step_warm_start: ${..time_step_current}\n",
      "    step_horizon: 0\n",
      "    step_horizon_decrease_per_epoch: 0\n",
      "    prob_forcing_agent: 0\n",
      "    prob_forcing_agent_decrease_per_epoch: 0\n",
      "  action_head:\n",
      "    log_std: -2\n",
      "    branch_type: true\n",
      "    use_layernorm: false\n",
      "  dynamics:\n",
      "    use_veh_dynamics_for_all: false\n",
      "    veh:\n",
      "      _target_: utils.dynamics.MultiPathPP\n",
      "      max_acc: 5\n",
      "      max_yaw_rate: 1.5\n",
      "      disable_neg_spd: false\n",
      "    cyc:\n",
      "      _target_: utils.dynamics.MultiPathPP\n",
      "      max_acc: 6\n",
      "      max_yaw_rate: 3\n",
      "      disable_neg_spd: false\n",
      "    ped:\n",
      "      _target_: utils.dynamics.MultiPathPP\n",
      "      max_acc: 7\n",
      "      max_yaw_rate: 7\n",
      "  differentiable_reward:\n",
      "    w_collision: 0\n",
      "    reduce_collsion_with_max: true\n",
      "    use_il_loss: true\n",
      "    l_pos:\n",
      "      weight: 0.1\n",
      "      criterion: SmoothL1Loss\n",
      "    l_rot:\n",
      "      weight: 10.0\n",
      "      criterion: SmoothL1Loss\n",
      "      angular_type: cosine\n",
      "    l_spd:\n",
      "      weight: 0.1\n",
      "      criterion: SmoothL1Loss\n",
      "  step_detach_hidden: -1\n",
      "  p_drop_hidden: -1.0\n",
      "  p_training_rollout_prior: 0.1\n",
      "  detach_state_policy: true\n",
      "  training_deterministic_action: true\n",
      "  waymo_post_processing:\n",
      "    k_pred: 6\n",
      "    use_ade: true\n",
      "    score_temperature: 100.0\n",
      "    mpa_nms_thresh: []\n",
      "    mtr_nms_thresh: []\n",
      "    aggr_thresh: []\n",
      "    n_iter_em: 3\n",
      "  sub_womd_reactive_replay:\n",
      "    activate: false\n",
      "    interactive_challenge: ${..interactive_challenge}\n",
      "    k_futures: 1\n",
      "    method_name: reactive_replay\n",
      "    authors:\n",
      "    - NAME1\n",
      "    - NAME2\n",
      "    affiliation: AFFILIATION\n",
      "    description: scr_womd\n",
      "    method_link: METHOD_LINK\n",
      "  sub_womd_joint_future_pred:\n",
      "    activate: false\n",
      "    interactive_challenge: ${..interactive_challenge}\n",
      "    k_futures: ${..waymo_post_processing.k_pred}\n",
      "    method_name: joint_future_pred\n",
      "    authors:\n",
      "    - NAME1\n",
      "    - NAME2\n",
      "    affiliation: AFFILIATION\n",
      "    description: scr_womd\n",
      "    method_link: METHOD_LINK\n",
      "  training_metrics:\n",
      "    w_vae_kl: 0.1\n",
      "    kl_balance_scale: -1\n",
      "    kl_free_nats: 0.01\n",
      "    kl_for_unseen_agent: true\n",
      "    w_diffbar_reward: 1.0\n",
      "    w_goal: 1.0\n",
      "    w_relevant_agent: 0\n",
      "    p_loss_for_irrelevant: -1.0\n",
      "    loss_for_teacher_forcing: true\n",
      "    step_training_start: 10\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    lr: 0.0003\n",
      "  lr_goal: ${.optimizer.lr}\n",
      "  lr_scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.StepLR\n",
      "    gamma: 0.5\n",
      "    step_size: 7\n",
      "  teacher_forcing_reactive_replay:\n",
      "    step_spawn_agent: 90\n",
      "    step_warm_start: ${..time_step_current}\n",
      "  teacher_forcing_joint_future_pred:\n",
      "    step_spawn_agent: ${..time_step_current}\n",
      "    step_warm_start: ${..time_step_current}\n",
      "  traffic_rule_checker:\n",
      "    enable_check_collided: false\n",
      "    enable_check_run_road_edge: false\n",
      "    enable_check_run_red_light: false\n",
      "    enable_check_passive: false\n",
      "datamodule:\n",
      "  _target_: data_modules.data_h5_womd.DataH5womd\n",
      "  data_dir: /home/gz0779601/codes/DataDriven_BehaviourModels/deep_learning_model/v1.0/data/h5_womd_sim_agent\n",
      "  filename_train: training\n",
      "  filename_val: validation\n",
      "  filename_test: testing\n",
      "  n_agent: 64\n",
      "  batch_size: 4\n",
      "  num_workers: 4\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: callbacks.wandb_callbacks.ModelCheckpointWB\n",
      "    dirpath: checkpoints/\n",
      "    filename: '{epoch:02d}'\n",
      "    monitor: val/loss\n",
      "    save_top_k: 1\n",
      "    save_last: true\n",
      "    mode: min\n",
      "    verbose: true\n",
      "  lr_monitor:\n",
      "    _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
      "  stochastic_weight_avg:\n",
      "    _target_: pytorch_lightning.callbacks.stochastic_weight_avg.StochasticWeightAveraging\n",
      "loggers:\n",
      "  wandb:\n",
      "    _target_: pytorch_lightning.loggers.WandbLogger\n",
      "    project: traffic_bots\n",
      "    group: null\n",
      "    name: local test 0712\n",
      "    notes: my_notes\n",
      "    tags: []\n",
      "    job_type: train\n",
      "    entity: yangyh408\n",
      "resume:\n",
      "  checkpoint: null\n",
      "  resume_trainer: true\n",
      "  model_overrides: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载配置信息到变量\n",
    "hydra.initialize(config_path=\"configs/\")\n",
    "config = hydra.compose(config_name=\"run.yaml\")\n",
    "\n",
    "# 输出配置信息\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2023\n"
     ]
    }
   ],
   "source": [
    "# 设置随机数种子\n",
    "seed_everything(config.seed, workers=True)\n",
    "\n",
    "# 实例化DataModule: 组织和管理数据加载\n",
    "datamodule: LightningDataModule = hydra.utils.instantiate(config.datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化回调函数\n",
    "callbacks: List[Callback] = []\n",
    "if \"callbacks\" in config:\n",
    "    for _, cb_conf in config.callbacks.items():\n",
    "        callbacks.append(hydra.utils.instantiate(cb_conf))\n",
    "\n",
    "# 实例化日志记录器\n",
    "loggers: List[LightningLoggerBase] = []\n",
    "if \"loggers\" in config:\n",
    "    for _, lg_conf in config.loggers.items():\n",
    "        loggers.append(hydra.utils.instantiate(lg_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "model: LightningModule = hydra.utils.instantiate(\n",
    "    config.model, data_size=datamodule.tensor_size_train, _recursive_=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myangyh408\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2024-07-12 14:02:25.075197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gz0779601/codes/DataDriven_BehaviourModels/deep_learning_model/v1.0/wandb/run-20240712_140221-22yjwixg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yangyh408/traffic_bots/runs/22yjwixg\" target=\"_blank\">local test 0712</a></strong> to <a href=\"https://wandb.ai/yangyh408/traffic_bots\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                           | Type                | Params\n",
      "------------------------------------------------------------------------\n",
      "0  | pre_processing                 | Sequential          | 0     \n",
      "1  | model                          | TrafficBots         | 3.3 M \n",
      "2  | action_head                    | ActionHead          | 50.3 K\n",
      "3  | train_metrics_train            | TrainingMetrics     | 0     \n",
      "4  | train_metrics_reactive_replay  | TrainingMetrics     | 0     \n",
      "5  | err_metrics_reactive_replay    | ErrorMetrics        | 0     \n",
      "6  | rule_metrics_reactive_replay   | TrafficRuleMetrics  | 0     \n",
      "7  | waymo_post_processing          | WaymoPostProcessing | 0     \n",
      "8  | womd_metrics_reactive_replay   | WOMDMetrics         | 0     \n",
      "9  | err_metrics_joint_future_pred  | ErrorMetrics        | 0     \n",
      "10 | rule_metrics_joint_future_pred | TrafficRuleMetrics  | 0     \n",
      "11 | womd_metrics_joint_future_pred | WOMDMetrics         | 0     \n",
      "12 | wosac_post_processing          | WOSACPostProcessing | 0     \n",
      "13 | wosac_metrics                  | WOSACMetrics        | 0     \n",
      "------------------------------------------------------------------------\n",
      "3.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 M     Total params\n",
      "6.792     Total estimated model params size (MB)\n",
      "/home/gz0779601/miniconda3/envs/traffic_bots/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/gz0779601/codes/DataDriven_BehaviourModels/deep_learning_model/v1.0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 85/61222 [02:43<32:41:31,  1.93s/it, loss=6.72, v_num=wixg]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gz0779601/miniconda3/envs/traffic_bots/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# 使用训练器进行训练\n",
    "trainer: Trainer = hydra.utils.instantiate(\n",
    "    config.trainer, callbacks=callbacks, logger=loggers, _convert_=\"partial\"\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 进行模型推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 下载训练后的模型\n",
    "\n",
    "> 模型保存在Weights And Biases对应项目中的Artifacts目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (TransientError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# 下载wandb记录的checkpoint\n",
    "def download_checkpoint(loggers, wb_ckpt) -> None:\n",
    "    print(f\"=> downloading checkpoint {wb_ckpt} into 'ckpt/model.ckpt'\")\n",
    "    if os.environ.get(\"LOCAL_RANK\", 0) == 0:\n",
    "        artifact = loggers[0].experiment.use_artifact(wb_ckpt, type=\"model\")\n",
    "        artifact_dir = artifact.download(\"ckpt\")\n",
    "\n",
    "loggers = [WandbLogger(\n",
    "  project=\"traffic_bots\",\n",
    "  entity=\"yangyh408\",\n",
    "  name=\"split inference\",\n",
    "  notes=\"jupyter single run\"\n",
    ")]\n",
    "\n",
    "# checkpoint_version = 'yangyh408/traffic_bots/285yb3yb:v59'\n",
    "checkpoint_version = 'yangyh408/traffic_bots/2cti1q5z:v41'\n",
    "download_checkpoint(loggers, checkpoint_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 `load_from_checkpoint` 方法，PyTorch Lightning 提供了一种方便的方法来管理和恢复模型训练过程，使得训练中断恢复和模型部署变得更加简单和高效。\n",
    "\n",
    "> 一般配合训练器 `trainer` 的 `save_checkpoint` 方法一起使用\n",
    "\n",
    "使用 load_from_checkpoint 的主要效果包括：\n",
    "\n",
    "+ 恢复模型权重：模型的权重会被恢复到保存检查点时的状态。\n",
    "+ 恢复优化器状态（如果保存）：如果在保存检查点时包含了优化器状态，则可以恢复优化器的状态，使得你可以继续训练而不会失去之前的优化进展。\n",
    "+ 恢复训练状态（如果保存）：可以恢复 epoch、batch 等训练状态，继续训练时从中断的地方开始。\n",
    "+ 推理：加载的模型可以用于推理，从而在新的数据上进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改模型的学习率\n",
    "# ckpt_path = \"ckpt/model.ckpt\"\n",
    "# checkpoint = torch.load(ckpt_path)\n",
    "# checkpoint['optimizer_states'][0]['param_groups'][0]['lr'] = 3e-4\n",
    "# checkpoint['optimizer_states'][0]['param_groups'][1]['lr'] = 3e-4\n",
    "# torch.save(checkpoint, \"ckpt/model_modified.ckpt\")\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "local_module_path = os.path.join(os.getcwd(), 'src')\n",
    "if local_module_path not in sys.path:\n",
    "    sys.path.append(local_module_path)\n",
    "\n",
    "from pl_modules.waymo_motion import WaymoMotion\n",
    "\n",
    "# 加载修改后的模型\n",
    "CKPG_NAME = \"2cti1q5z\"\n",
    "CKPG_VER = \"v41\"\n",
    "\n",
    "ckpt_path = f\"checkpoints/{CKPG_NAME}_{CKPG_VER}.ckpt\"\n",
    "checkpoint_version = f\"yangyh408/traffic_bots/{CKPG_NAME}:{CKPG_VER}\"\n",
    "\n",
    "model = WaymoMotion.load_from_checkpoint(ckpt_path, wb_artifact=checkpoint_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 运行单批次推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "\n",
    "from data_modules.data_h5_womd import DataH5womd\n",
    "DATA_DIR = \"/home/gz0779601/codes/DataDriven_BehaviourModels/deep_learning_model/v1.0/data/h5_womd_sim_agent\"\n",
    "# DATA_DIR = \"/media/yangyh408/4A259082626F01B9/h5_womd_sim_agent\"\n",
    "\n",
    "single_data = DataH5womd(\n",
    "    data_dir = DATA_DIR,\n",
    "    filename_train = \"training\",\n",
    "    filename_val = \"validation\",\n",
    "    filename_test = \"testing\",\n",
    "    n_agent = 64,\n",
    "    batch_size = 4,\n",
    "    num_workers = 4,\n",
    ")\n",
    "single_data.setup(stage=\"validate\")\n",
    "val_dataloader = single_data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "target_batch_idx = 3\n",
    "for batch_idx, batch in enumerate(val_dataloader):\n",
    "    if target_batch_idx == None or batch_idx == target_batch_idx:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            rollout = model.manual_reactive_replay(batch=batch, batch_idx=batch_idx, log_video=False)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 训练架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 pytorch-lightning框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 框架内各模块的功能\n",
    "\n",
    "    1. DataModule\n",
    "\n",
    "        DataModule 主要负责数据加载和预处理，将数据准备好以供模型训练使用。它将数据集的准备、划分（如训练集、验证集、测试集）、数据加载器（DataLoader）的定义等任务进行封装，使得在训练过程中可以轻松地管理和调用数据。\n",
    "\n",
    "    2. Model\n",
    "\n",
    "        Model 是定义和组织深度学习模型及其训练过程的核心。它包含了模型的结构（网络架构）、前向传播逻辑、损失函数定义等。\n",
    "\n",
    "    3. Logger\n",
    "\n",
    "        Logger 用于记录和存储训练过程中的指标、损失、学习率等信息，以便后续分析和可视化。\n",
    "\n",
    "    4. Callbacks\n",
    "\n",
    "        Callbacks 提供了一种机制，允许在训练过程中插入自定义的操作、逻辑或者修改训练行为。常见的用途包括记录指标、模型检查点、动态调整学习率等。\n",
    "\n",
    "        本模型使用了三种回调函数：\n",
    "\n",
    "        + `ModelCheckpointWB`: 用于向wandb传输最优的checkpoints信息\n",
    "        + `LearningRateMonitor`: 用于监控和记录训练过程中学习率的变化情况\n",
    "        + `StochasticWeightAveraging`: 用于在训练过程中实现随机权重平均（SWA）。SWA 是一种在训练结束时对模型参数进行平均的技术，旨在提升模型的泛化能力和鲁棒性。\n",
    "\n",
    "\n",
    "    5. Resume\n",
    "\n",
    "        Resume 指的是从之前保存的检查点恢复训练的操作。它允许在中断的训练任务上继续进行，而不必从头开始重新训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `trainer`训练器的调度流程\n",
    "\n",
    "    1. 初始化 Trainer\n",
    "\n",
    "        当你 Trainer 对象时，它会按照预设的参数配置自动初始化，同时也会初始化相关的模块。例如，初始化 Logger、注册 Callbacks 等。\n",
    "\n",
    "    2. 准备数据（DataModule）\n",
    "\n",
    "        在 Trainer 开始训练之前，会先调用 DataModule 的准备数据阶段。这包括调用 prepare_data() 方法来下载、预处理数据，然后调用 setup() 方法来设置数据集和数据加载器。\n",
    "\n",
    "        + `DataLoader` 是 PyTorch 的基础组件，负责数据的批次加载和处理。\n",
    "\n",
    "        + `DataModule` 是 PyTorch Lightning 的高级组件，用于更系统化地处理数据，包含数据下载、预处理和定义不同阶段的数据加载器（训练、验证、测试）。\n",
    "\n",
    "    3. 初始化模型（Model）\n",
    "\n",
    "        一旦数据准备完成后，Trainer 开始初始化 Model。这包括实例化模型对象、配置优化器和损失函数等。模型的初始化通常是在数据准备完成后，确保可以正确加载数据并进行训练。\n",
    "\n",
    "    4. 训练循环\n",
    "\n",
    "        一旦模型和数据都准备就绪，Trainer 开始执行训练循环。在训练循环中，它会按照以下步骤调度模块的使用：\n",
    "\n",
    "        + 每个 Epoch 开始：\n",
    "        \n",
    "            在每个 epoch 开始时，Trainer 会依次调用注册的 Callbacks 的 on_epoch_start 方法，执行一些特定于 epoch 的操作，如动态调整学习率、记录 epoch 开始时间等。\n",
    "        \n",
    "        + Batch 训练：\n",
    "        \n",
    "            每次迭代中，Trainer 会从 DataModule 中获取一个 batch 的数据，并将其送入 Model 进行前向传播、损失计算、反向传播和参数更新。\n",
    "        \n",
    "        + Logging 和 Callbacks：\n",
    "            \n",
    "            在每个训练步骤结束时，Trainer 会更新指标（如损失、准确率等）并将其记录到 Logger 中。同时，会调用注册的 Callbacks 的相应方法，例如 on_batch_end，允许用户执行自定义操作。\n",
    "        \n",
    "        + 每个 Epoch 结束：\n",
    "        \n",
    "            当一个 epoch 结束时，Trainer 会调用 DataModule 的 train_dataloader() 来获取下一个 epoch 的训练数据。然后，会调用注册的 Callbacks 的 on_epoch_end 方法执行一些 epoch 结束时的操作，如模型验证、保存检查点等。\n",
    "    \n",
    "    5. 验证和测试\n",
    "    \n",
    "        在训练的过程中，Trainer 还会根据配置周期性地执行验证和测试步骤。它会使用 DataModule 提供的验证和测试数据集，并调用 Model 进行推理或评估，同时记录和更新指标。\n",
    "\n",
    "    6. 检查点和恢复\n",
    "        \n",
    "        如果中断了训练或需要从之前的检查点恢复训练，Trainer 在初始化时会检查是否有指定的 resume_from_checkpoint 参数，并在需要时加载模型和优化器的状态，从中断的地方继续训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_bots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
